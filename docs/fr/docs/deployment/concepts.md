# Concepts de d√©ploiement

Lors du d√©ploiement d'une application **FastAPI**, ou en fait, de n'importe quel type d'API web, il y a plusieurs concepts qui vous int√©ressent probablement, et en les utilisant vous pouvez trouver la **mani√®re la plus appropri√©e** de **d√©ployer votre application**.

Voici quelques-uns des concepts importants :

* S√©curit√© - HTTPS
* Ex√©cution au d√©marrage
* Red√©marrage
* R√©plication (nombre de processus en cours d'ex√©cution)
* M√©moire
* √âtapes pr√©c√©dentes avant le d√©marrage

Nous verrons comment ils affectent les **d√©ploiements**.

En fin de compte, l'objectif ultime est de pouvoir **servir vos clients API** d'une mani√®re **s√©curis√©e**, d'**√©viter les perturbations** et d'utiliser les **ressources informatiques** (par exemple les serveurs distants/machines virtuelles) aussi efficacement que possible. üöÄ

Je vais vous en dire un peu plus sur ces **concepts** ici, et j'esp√®re que cela vous donnera l'**intuition** dont vous aurez besoin pour d√©cider comment d√©ployer votre API dans des environnements tr√®s diff√©rents, peut-√™tre m√™me dans des **futurs** qui n'existent pas encore.

En tenant compte de ces concepts, vous pourrez **√©valuer et concevoir** la meilleure fa√ßon de d√©ployer **vos propres API**.

Dans les prochains chapitres, je vous donnerai plus de **recettes concr√®tes** pour d√©ployer des applications FastAPI.

Mais pour l'instant, v√©rifions ces **id√©es conceptuelles** importantes. Ces concepts s'appliquent √©galement √† tout autre type d'API web. üí°

## S√©curit√© - HTTPS

Dans le [chapitre pr√©c√©dent sur le HTTPS](./https.md){.internal-link target=_blank}, nous avons appris comment le HTTPS assure le cryptage de votre API.

Nous avons √©galement vu que HTTPS est normalement fourni par un composant **externe** √† votre serveur d'application, un **TLS Termination Proxy**.

Et il doit y avoir quelque chose en charge du **renouvellement des certificats HTTPS**, cela peut √™tre le m√™me composant ou quelque chose de diff√©rent.

### Exemples d'outils pour HTTPS

Voici quelques-uns des outils que vous pouvez utiliser en tant que proxy de terminaison TLS :

* Traefik
    * Traefik g√®re automatiquement les renouvellements de certificats ‚ú®
* Caddy
    G√®re automatiquement les renouvellements de certificats ‚ú® * Caddy
* Nginx
    * Avec un composant externe comme Certbot pour les renouvellements de certificats
* HAProxy
    * Avec un composant externe comme Certbot pour le renouvellement des certificats
* Kubernetes avec un contr√¥leur Ingress comme Nginx
    * Avec un composant externe comme cert-manager pour le renouvellement des certificats.
* G√©r√© en interne par un fournisseur de cloud dans le cadre de ses services (voir ci-dessous üëá)

Une autre option consiste √† utiliser un **service en nuage** qui effectue une plus grande partie du travail, y compris la mise en place de HTTPS. Il pourrait avoir certaines restrictions ou vous faire payer plus cher, etc. Mais dans ce cas, vous n'auriez pas √† configurer vous-m√™me un proxy de terminaison TLS.

Je vous montrerai des exemples concrets dans les prochains chapitres.

---

Les concepts suivants √† prendre en compte concernent le programme qui ex√©cute votre API (par exemple Uvicorn).

## Programme et processus

Nous parlerons beaucoup du "**processus**", il est donc utile de clarifier ce qu'il signifie, et quelle est la diff√©rence avec le mot "**programme**".

### Qu'est-ce qu'un programme ?

Le mot **programme** est couramment utilis√© pour d√©crire de nombreuses choses :

* Le **code** que vous √©crivez, les **fichiers Python**.
* Le **fichier** qui peut √™tre **ex√©cut√©** par le syst√®me d'exploitation, par exemple : `python`, `python.exe` ou `uvicorn`.
* Un programme particulier lorsqu'il **s'ex√©cute** sur le syst√®me d'exploitation, utilise le processeur et stocke des donn√©es dans la m√©moire. On l'appelle aussi **processus**.

### Qu'est-ce qu'un processus ?

Le mot **processus** est normalement utilis√© de mani√®re plus sp√©cifique, en se r√©f√©rant uniquement √† ce qui s'ex√©cute dans le syst√®me d'exploitation (comme dans le dernier point ci-dessus) :

* Un programme particulier pendant qu'il **s'ex√©cute** sur le syst√®me d'exploitation.
    * Cela ne fait pas r√©f√©rence au fichier, ni au code, mais **sp√©cifiquement** √† la chose qui est **ex√©cut√©e** et g√©r√©e par le syst√®me d'exploitation.
* Tout programme, tout code, **ne peut faire des choses** que lorsqu'il est **ex√©cut√©**. Ainsi, lorsqu'un **processus est en cours d'ex√©cution**.
* Le processus peut √™tre **termin√©** (ou "tu√©") par vous ou par le syst√®me d'exploitation. √Ä ce moment-l√†, il cesse de fonctionner ou d'√™tre ex√©cut√©, et il ne peut **plus faire de choses**.
* Chaque application en cours d'ex√©cution sur votre ordinateur a un processus derri√®re elle, chaque programme en cours d'ex√©cution, chaque fen√™tre, etc. Et il y a normalement de nombreux processus en cours d'ex√©cution **en m√™me temps** lorsqu'un ordinateur est allum√©.
* Il peut y avoir **plusieurs processus** du **m√™me programme** en cours d'ex√©cution en m√™me temps.

Si vous consultez le "gestionnaire de t√¢ches" ou le "moniteur syst√®me" (ou des outils similaires) de votre syst√®me d'exploitation, vous pourrez voir un grand nombre de ces processus en cours d'ex√©cution.

Par exemple, vous verrez probablement que plusieurs processus ex√©cutent le m√™me programme de navigation (Firefox, Chrome, Edge, etc.). Ils ex√©cutent normalement un processus par onglet, plus quelques autres processus suppl√©mentaires.

<img class="shadow" src="../../../en/docs/img/deployment/concepts/image01.png">

---

Maintenant que nous connaissons la diff√©rence entre les termes **processus** et **programme**, continuons √† parler des d√©ploiements.

## Ex√©cution au d√©marrage

Dans la plupart des cas, lorsque vous cr√©ez une API web, vous souhaitez qu'elle soit **toujours en cours d'ex√©cution**, sans interruption, afin que vos clients puissent toujours y acc√©der. Bien s√ªr, sauf si vous avez une raison sp√©cifique pour laquelle vous voulez qu'elle ne fonctionne que dans certaines situations, mais la plupart du temps, vous voulez qu'elle fonctionne en permanence et qu'elle soit **disponible**.

### Dans un serveur distant

Lorsque vous configurez un serveur distant (un serveur cloud, une machine virtuelle, etc.), la chose la plus simple que vous puissiez faire est de lancer Uvicorn (ou similaire) manuellement, de la m√™me mani√®re que vous le faites lorsque vous d√©veloppez localement.

Et cela fonctionnera et sera utile **pendant le d√©veloppement**.

Mais si votre connexion au serveur est perdue, le **processus d'ex√©cution** mourra probablement.

Et si le serveur est red√©marr√© (par exemple apr√®s des mises √† jour ou des migrations depuis le fournisseur de cloud), vous ne le remarquerez probablement **pas**. Et pour cette raison, vous ne saurez m√™me pas que vous devez red√©marrer le processus manuellement. Ainsi, votre API restera simplement morte. üò±

### Ex√©cuter automatiquement au d√©marrage

En g√©n√©ral, vous voudrez probablement que le programme serveur (par exemple Uvicorn) soit lanc√© automatiquement au d√©marrage du serveur, et sans avoir besoin d'une **intervention humaine**, pour avoir un processus toujours en cours d'ex√©cution avec votre API (par exemple Uvicorn ex√©cutant votre application FastAPI).

### Programme s√©par√©

Pour y parvenir, vous aurez normalement un **programme s√©par√©** qui s'assurera que votre application est ex√©cut√©e au d√©marrage. Et dans de nombreux cas, il s'assurera √©galement que d'autres composants ou applications sont √©galement lanc√©s, par exemple, une base de donn√©es.

### Exemples d'outils √† ex√©cuter au d√©marrage

Voici quelques exemples d'outils qui peuvent faire ce travail :

* Docker
* Kubernetes
* Docker Compose
* Docker en mode Swarm
* Systemd
* Superviseur
* G√©r√© en interne par un fournisseur de services en nuage dans le cadre de ses services
* D'autres encore...

Je vous donnerai des exemples plus concrets dans les prochains chapitres.

## Red√©marrages

Tout comme vous voulez vous assurer que votre application est lanc√©e au d√©marrage, vous voulez probablement aussi vous assurer qu'elle est **red√©marr√©e** apr√®s des √©checs.

### Nous faisons des erreurs

En tant qu'humains, nous faisons des **erreurs**, tout le temps. Les logiciels ont presque *toujours* des **bugs** cach√©s √† diff√©rents endroits. üêõ

Et nous, en tant que d√©veloppeurs, continuons √† am√©liorer le code au fur et √† mesure que nous trouvons ces bogues et que nous impl√©mentons de nouvelles fonctionnalit√©s (en ajoutant √©ventuellement de nouveaux bogues aussi üòÖ).

### Les petites erreurs sont automatiquement g√©r√©es

Lors de la cr√©ation d'API web avec FastAPI, s'il y a une erreur dans notre code, FastAPI la contiendra normalement √† la requ√™te unique qui a d√©clench√© l'erreur. üõ°

Le client recevra une **500 Internal Server Error** pour cette requ√™te, mais l'application continuera √† fonctionner pour les requ√™tes suivantes au lieu de se planter compl√®tement.

### Les plus grosses erreurs - les plantages

N√©anmoins, il peut y avoir des cas o√π nous √©crivons du code qui **crash l'application enti√®re** faisant planter Uvicorn et Python. üí•

Et pourtant, vous ne voudriez probablement pas que l'application reste morte parce qu'il y a eu une erreur √† un endroit, vous voudriez probablement qu'elle **continue √† fonctionner** au moins pour les *op√©rations de parcours* qui ne sont pas cass√©es.

### Red√©marrer apr√®s un crash

Mais dans les cas d'erreurs vraiment graves qui font planter le **processus** en cours d'ex√©cution, vous voudriez un composant externe qui soit charg√© de **red√©marrer** le processus, au moins deux ou trois fois...

!!! astuce
    ...Bien que si l'application enti√®re **se plante imm√©diatement**, cela n'a probablement pas de sens de la red√©marrer sans cesse. Mais dans ce cas, vous le remarquerez probablement pendant le d√©veloppement, ou au moins juste apr√®s le d√©ploiement.

    Concentrons-nous donc sur les cas principaux, o√π le syst√®me pourrait se bloquer enti√®rement dans certains cas particuliers **dans le futur**, et o√π il est toujours utile de le red√©marrer.

Vous voudriez probablement que la chose charg√©e de red√©marrer votre application soit un **composant externe**, parce qu'√† ce moment-l√†, la m√™me application avec Uvicorn et Python a d√©j√† plant√©, donc il n'y a rien dans le m√™me code de la m√™me application qui puisse faire quoi que ce soit √† ce sujet.

### Exemples d'outils pour red√©marrer automatiquement

Dans la plupart des cas, le m√™me outil qui est utilis√© pour **ex√©cuter le programme au d√©marrage** est √©galement utilis√© pour g√©rer les **red√©marrages** automatiques.

Par exemple, cela peut √™tre g√©r√© par :

* Docker
* Kubernetes
* Docker Compose
* Docker en mode Swarm
* Systemd
* Superviseur
* G√©r√© en interne par un fournisseur de services en nuage dans le cadre de ses services
* Autres...

## R√©plication - Processus et m√©moire

Avec une application FastAPI, utilisant un programme serveur comme Uvicorn, l'ex√©cuter une fois dans **un processus** peut servir plusieurs clients simultan√©ment.

Mais dans de nombreux cas, vous voudrez ex√©cuter plusieurs processus de travail en m√™me temps.

### Processus multiples - Travailleurs

Si vous avez plus de clients que ce qu'un seul processus peut g√©rer (par exemple, si la machine virtuelle n'est pas trop grande) et que vous disposez de **multiples c≈ìurs** dans le processeur du serveur, vous pouvez alors avoir **multiples processus** fonctionnant avec la m√™me application en m√™me temps, et distribuer toutes les demandes entre eux.

Lorsque vous ex√©cutez **plusieurs processus** du m√™me programme API, ils sont commun√©ment appel√©s **workers**.

### Processus et ports de travailleur

Vous vous souvenez de la documentation [√Ä propos de HTTPS](./https.md){.internal-link target=_blank} selon laquelle un seul processus peut √™tre √† l'√©coute sur une combinaison de port et d'adresse IP dans un serveur ?

C'est toujours le cas.

Ainsi, pour pouvoir avoir **plusieurs processus** en m√™me temps, il doit y avoir **un seul processus √† l'√©coute sur un port** qui transmet ensuite la communication √† chaque processus travailleur d'une mani√®re ou d'une autre.

### M√©moire par processus

Lorsque le programme charge des √©l√©ments en m√©moire, par exemple un mod√®le d'apprentissage automatique dans une variable ou le contenu d'un gros fichier dans une variable, tout cela **consomme un peu de la m√©moire (RAM)** du serveur.

Et les processus multiples ne **partagent normalement pas de m√©moire**. Cela signifie que chaque processus en cours d'ex√©cution a ses propres √©l√©ments, variables et m√©moire. Et si vous consommez une grande quantit√© de m√©moire dans votre code, **chaque processus** consommera une quantit√© √©quivalente de m√©moire.

### M√©moire du serveur

Par exemple, si votre code charge un mod√®le d'apprentissage automatique d'une taille de **1 Go**, lorsque vous ex√©cutez un processus avec votre API, il consommera au moins 1 Go de RAM. Et si vous lancez **4 processus** (4 travailleurs), chacun consommera 1 Go de RAM. Au total, votre API consommera donc **4 Go de RAM**.

Et si votre serveur distant ou votre machine virtuelle ne dispose que de 3 Go de RAM, essayer de charger plus de 4 Go de RAM posera des probl√®mes. üö®

### Processus multiples - Un exemple

Dans cet exemple, il y a un **processus gestionnaire** qui d√©marre et contr√¥le deux **processus travailleurs**.

Ce processus gestionnaire est probablement celui qui √©coute sur le **port** de l'IP. Il transmet toutes les communications aux processus de travail.

Ces processus travailleurs seraient ceux qui ex√©cutent votre application, ils effectueraient les principaux calculs pour recevoir une **requ√™te** et renvoyer une **r√©ponse**, et ils chargeraient tout ce que vous mettez dans les variables en RAM.

<img src="../../../en/docs/img/deployment/concepts/process-ram.svg">

Et bien s√ªr, sur la m√™me machine, d'autres **processus** sont probablement en cours d'ex√©cution, en dehors de votre application.

Un d√©tail int√©ressant est que le pourcentage de **CPU utilis√©** par chaque processus peut **varier** consid√©rablement dans le temps, mais la **m√©moire (RAM)** reste normalement plus ou moins **stable**.

Si vous avez une API qui effectue une quantit√© comparable de calculs √† chaque fois et que vous avez beaucoup de clients, l'**utilisation de l'UC** sera probablement *√©galement stable* (au lieu d'augmenter et de diminuer rapidement).

### Exemples d'outils et de strat√©gies de r√©plication

Il peut y avoir plusieurs approches pour y parvenir, et je vous en dirai plus sur des strat√©gies sp√©cifiques dans les prochains chapitres, par exemple lorsque je parlerai de Docker et des conteneurs.

La principale contrainte √† prendre en compte est qu'il doit y avoir un **seul** composant g√©rant le **port** dans l'**IP publique**. Il doit ensuite avoir un moyen de **transmettre** la communication aux **processus/travailleurs** r√©pliqu√©s.

Voici quelques combinaisons et strat√©gies possibles :

* **Gunicorn** g√©rant des **travailleurs Uvicorn**
    * Gunicorn serait le **gestionnaire de processus** √©coutant sur l'**IP** et le **port**, la r√©plication se ferait en ayant **plusieurs processus de travailleur Uvicorn**.
**Uvicorn** g√®re **les travailleurs Uvicorn**.
    * Un **gestionnaire de processus** Uvicorn √©couterait sur **IP** et **port**, et d√©marrerait **plusieurs processus de travailleur Uvicorn**.
* **Kubernetes** et autres **syst√®mes de conteneurs distribu√©s**
    * Quelque chose dans la couche **Kubernetes** √©couterait sur **IP** et **port**. La r√©plication se ferait en ayant **plusieurs conteneurs**, chacun avec **un processus Uvicorn** en cours d'ex√©cution.
* Les **services en nuage** qui s'en chargent pour vous
    * Le service en nuage va probablement **g√©rer la r√©plication pour vous**. Il vous permettra peut-√™tre de d√©finir **un processus √† ex√©cuter**, ou une **image de conteneur** √† utiliser, dans tous les cas, il s'agira tr√®s probablement **d'un seul processus Uvicorn**, et le service cloud se chargera de le r√©pliquer.

!!! conseil
    Ne vous inqui√©tez pas si certains de ces √©l√©ments concernant les **conteneurs**, Docker ou Kubernetes n'ont pas encore beaucoup de sens.

    Je vous en dirai plus sur les images de conteneurs, Docker, Kubernetes, etc. dans un prochain chapitre : [D√©ploiement - D√©ployer avec Docker](./docker.md){.internal-link target=_blank}.
## √âtapes pr√©c√©dentes avant le d√©marrage

Dans de nombreux cas, vous souhaitez effectuer certaines √©tapes **avant de d√©marrer** votre application.

Par exemple, vous pourriez vouloir ex√©cuter des **migrations de base de donn√©es**.

Mais dans la plupart des cas, vous ne voudrez ex√©cuter ces √©tapes qu'une seule fois.

Vous voudrez donc disposer d'un **processus unique** pour ex√©cuter ces **√©tapes pr√©c√©dentes**, avant de d√©marrer l'application.

Et vous devrez vous assurer que c'est un seul processus qui ex√©cute ces √©tapes pr√©c√©dentes *m√™me* si par la suite, vous d√©marrez **plusieurs processus** (plusieurs travailleurs) pour l'application elle-m√™me. Si ces √©tapes √©taient ex√©cut√©es par **plusieurs processus**, ils **dupliqueraient** le travail en l'ex√©cutant en **parall√®le**, et si les √©tapes √©taient quelque chose de d√©licat comme une migration de base de donn√©es, elles pourraient causer des conflits les unes avec les autres.

Bien s√ªr, il y a des cas o√π il n'y a pas de probl√®me √† ex√©cuter les √©tapes pr√©c√©dentes plusieurs fois, dans ce cas, c'est beaucoup plus facile √† g√©rer.

!!! conseil
    Gardez √©galement √† l'esprit que, selon votre configuration, dans certains cas, vous **n'aurez m√™me pas besoin d'√©tapes pr√©c√©dentes** avant de d√©marrer votre application.

    Dans ce cas, vous n'aurez pas √† vous soucier de tout cela. ü§∑

### Exemples de strat√©gies pour les √©tapes pr√©c√©dentes

Cela **d√©pendra fortement** de la fa√ßon dont vous **d√©ployez votre syst√®me**, et sera probablement li√© √† la fa√ßon dont vous d√©marrez les programmes, en g√©rant les red√©marrages, etc.

Voici quelques id√©es possibles :

* Un "Init Container" dans Kubernetes qui s'ex√©cute avant votre conteneur d'application.
* Un script bash qui ex√©cute les √©tapes pr√©c√©dentes et d√©marre ensuite votre application.
    * Vous auriez toujours besoin d'un moyen de d√©marrer/red√©marrer *ce* script bash, de d√©tecter les erreurs, etc.

!!! astuce
    Je vous donnerai des exemples plus concrets pour faire cela avec des conteneurs dans un prochain chapitre : [D√©ploiement - D√©ployer avec Docker](./docker.md){.internal-link target=_blank}.

## Utilisation des ressources

Votre (vos) serveur(s) est (sont) une **ressource**, vous pouvez consommer ou **utiliser**, avec vos programmes, le temps de calcul sur les CPU, et la m√©moire RAM disponible.

Quelle part des ressources du syst√®me souhaitez-vous consommer/utiliser ? Il peut √™tre facile de penser "pas beaucoup", mais en r√©alit√©, vous voudrez probablement consommer **le plus possible sans planter**.

Si vous payez pour 3 serveurs mais que vous n'utilisez qu'une petite partie de leur RAM et de leur CPU, vous √™tes probablement en train de **gaspiller de l'argent** üí∏, et probablement de **gaspiller l'√©nergie √©lectrique du serveur** üåé, etc.

Dans ce cas, il serait pr√©f√©rable de n'avoir que deux serveurs et d'utiliser un pourcentage plus √©lev√© de leurs ressources (CPU, m√©moire, disque, bande passante r√©seau, etc.).

D'un autre c√¥t√©, si vous avez 2 serveurs et que vous utilisez **100% de leur CPU et de leur RAM**, √† un moment donn√©, un processus demandera plus de m√©moire, et le serveur devra utiliser le disque comme "m√©moire" (ce qui peut √™tre des milliers de fois plus lent), ou m√™me **crash**. Ou bien un processus peut avoir besoin d'effectuer un calcul et devra attendre que l'unit√© centrale soit √† nouveau libre.

Dans ce cas, il serait pr√©f√©rable d'avoir **un serveur suppl√©mentaire** et d'y ex√©cuter quelques processus afin qu'ils aient **suffisamment de RAM et de temps CPU**.

Il est √©galement possible que, pour une raison ou une autre, votre API connaisse une **pouss√©e** d'utilisation. Elle est peut-√™tre devenue virale, ou d'autres services ou bots commencent √† l'utiliser. Vous voudrez peut-√™tre disposer de ressources suppl√©mentaires pour vous prot√©ger dans ces cas-l√†.

Vous pouvez fixer un **nombre arbitraire** √† cibler, par exemple, quelque chose **entre 50 % et 90 %** de l'utilisation des ressources. Le fait est que ce sont probablement les choses principales que vous voudrez mesurer et utiliser pour ajuster vos d√©ploiements.

Vous pouvez utiliser des outils simples comme `htop` pour voir le CPU et la RAM utilis√©s sur votre serveur ou la quantit√© utilis√©e par chaque processus. Ou vous pouvez utiliser des outils de surveillance plus complexes, qui peuvent √™tre distribu√©s √† travers les serveurs, etc.

## R√©capitulation

Vous avez lu ici quelques-uns des principaux concepts que vous devrez probablement avoir √† l'esprit lorsque vous d√©ciderez de la mani√®re de d√©ployer votre application :

* S√©curit√© - HTTPS
* Ex√©cution au d√©marrage
* Red√©marrage
* R√©plication (nombre de processus en cours d'ex√©cution)
* M√©moire
* √âtapes pr√©c√©dentes avant le d√©marrage

Comprendre ces id√©es et comment les appliquer devrait vous donner l'intuition n√©cessaire pour prendre toute d√©cision lors de la configuration et de l'ajustement de vos d√©ploiements. ü§ì

Dans les prochaines sections, je vous donnerai des exemples plus concrets de strat√©gies possibles que vous pouvez suivre. üöÄ
